{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = '../../raw_train_artifact'\n",
    "test_path = '../../raw_test_artifact'\n",
    "embedding_path = '../../embedding_artifact'\n",
    "input_path = '../../input_artifact'\n",
    "input_split_path = '../../input_artifact/input_split'\n",
    "model_path = '../../model_artifact'\n",
    "output_path = '../../output_artifact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "gc.enable()\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',120)\n",
    "pd.set_option('display.max_rows',2000)\n",
    "pd.set_option('precision',5)\n",
    "pd.set_option('float_format', '{:.5f}'.format)\n",
    "\n",
    "import tqdm\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:43:46 INFO: Restart notebook\n",
      "==========================\n",
      "Tue Jun  2 11:43:46 2020\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "log_path = '[1.1]Hugging Face Transformer Experiment.log'\n",
    "    \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-s: %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "fh = logging.FileHandler(log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "logger.info(f'Restart notebook\\n==========================\\n{time.ctime()}\\n==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:43:46 INFO: Device in Use: cuda\n",
      "11:43:46 INFO: CUDA Memory: Total 8.00 GB, Cached 0.00 GB, Allocated 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(DEVICE).total_memory/1024**3\n",
    "c = torch.cuda.memory_cached(DEVICE)/1024**3\n",
    "a = torch.cuda.memory_allocated(DEVICE)/1024**3\n",
    "logger.info('CUDA Memory: Total {:.2f} GB, Cached {:.2f} GB, Allocated {:.2f} GB'.format(t,c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with torch padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1] torch.Size([2, 3, 120])\n"
     ]
    }
   ],
   "source": [
    "inp_1 = torch.from_numpy(np.ones((3, 120))).float()\n",
    "inp_2 = torch.from_numpy(np.ones((1, 120))).float()\n",
    "inp = [inp_1, inp_2]\n",
    "inp_len = [t.shape[0] for t in inp]\n",
    "pad_inp = torch.nn.utils.rnn.pad_sequence(inp, batch_first=True, padding_value=0)\n",
    "print(inp_len, pad_inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 120])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_inp.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256])\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(input_size=120, hidden_size=128, num_layers=2, bias=True, batch_first=True, bidirectional=True)\n",
    "out = lstm(pad_inp)\n",
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(input_size=120, hidden_size=128, num_layers=2, bias=True, bidirectional=True)\n",
    "out = lstm(pad_inp.permute(1,0,2))\n",
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3860"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del configuration, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig, AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = AlbertConfig()\n",
    "model = AlbertModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.from_numpy(np.concatenate([np.ones((10, 5, 128)), np.zeros((10, 5, 128))], axis=1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 128])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out= model(inputs_embeds=inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 4096])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0415586 , -0.700448  , -0.23963146, ..., -0.34111258,\n",
       "        -0.88970816,  2.0453863 ],\n",
       "       [-1.0419453 , -0.7001726 , -0.24012905, ..., -0.34073353,\n",
       "        -0.8900057 ,  2.0456576 ],\n",
       "       [-1.0417546 , -0.7000878 , -0.24050954, ..., -0.34136513,\n",
       "        -0.8902673 ,  2.0448096 ],\n",
       "       ...,\n",
       "       [-1.0415502 , -0.70019853, -0.23981182, ..., -0.34107703,\n",
       "        -0.8901159 ,  2.0457187 ],\n",
       "       [-1.0413502 , -0.6995464 , -0.240383  , ..., -0.34042382,\n",
       "        -0.8905616 ,  2.0456984 ],\n",
       "       [-1.0413843 , -0.70032   , -0.23944165, ..., -0.34181798,\n",
       "        -0.89004594,  2.0447192 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
