{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = '../../raw_train_artifact'\n",
    "test_path = '../../raw_test_artifact'\n",
    "embedding_path = '../../embedding_artifact'\n",
    "input_path = '../../input_artifact'\n",
    "input_split_path = '../../input_artifact/input_split'\n",
    "model_path = '../../model_artifact'\n",
    "output_path = '../../output_artifact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "gc.enable()\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',120)\n",
    "pd.set_option('display.max_rows',2000)\n",
    "pd.set_option('precision',5)\n",
    "pd.set_option('float_format', '{:.5f}'.format)\n",
    "\n",
    "import tqdm\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:40:10 INFO: Restart notebook\n",
      "==========================\n",
      "Thu Jun  4 07:40:10 2020\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "log_path = '[1.3]LSTM with Creative, Advertiser & Product Embedding Sequence.log'\n",
    "    \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-s: %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "fh = logging.FileHandler(log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "sh.setLevel(logging.INFO)\n",
    "sh.setFormatter(formatter)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "logger.info(f'Restart notebook\\n==========================\\n{time.ctime()}\\n==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:40:10 INFO: Device in Use: cuda\n",
      "07:40:10 INFO: CUDA Memory: Total 8.00 GB, Cached 0.00 GB, Allocated 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info('Device in Use: {}'.format(DEVICE))\n",
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(DEVICE).total_memory/1024**3\n",
    "c = torch.cuda.memory_cached(DEVICE)/1024**3\n",
    "a = torch.cuda.memory_allocated(DEVICE)/1024**3\n",
    "logger.info('CUDA Memory: Total {:.2f} GB, Cached {:.2f} GB, Allocated {:.2f} GB'.format(t,c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embed_artifact = {\n",
    "    'creative': {\n",
    "        'embedding_artifact': r'C:\\JupyterNotebook\\Tencent-Ads-Algo-Comp-2020\\embedding_artifact\\creative_id_embed_s160_w64_cbow_38168zon',\n",
    "        'train_file_prefix': 'train_creative_agg_user',\n",
    "        'test_file_prefix': 'test_creative_agg_user'\n",
    "    },\n",
    "    'ad': {\n",
    "        'embedding_artifact': r'C:\\JupyterNotebook\\Tencent-Ads-Algo-Comp-2020\\embedding_artifact\\ad_id_embed_s160_w64_cbow_ibfi8g78',\n",
    "        'train_file_prefix': 'train_ad_agg_user',\n",
    "        'test_file_prefix': 'test_ad_agg_user'\n",
    "    },\n",
    "    'advertiser': {\n",
    "        'embedding_artifact': r'C:\\JupyterNotebook\\Tencent-Ads-Algo-Comp-2020\\embedding_artifact\\advertiser_id_embed_s128_w64_cbow_n4re8tds',\n",
    "        'train_file_prefix': 'train_advertiser_agg_user',\n",
    "        'test_file_prefix': 'test_advertiser_agg_user'\n",
    "    },\n",
    "    'product': {\n",
    "        'embedding_artifact': r'C:\\JupyterNotebook\\Tencent-Ads-Algo-Comp-2020\\embedding_artifact\\product_id_embed_s128_w64_cbow_8yemmp45',\n",
    "        'train_file_prefix': 'train_product_agg_user',\n",
    "        'test_file_prefix': 'test_product_agg_user'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_truth(split_id, logger=None):\n",
    "    \"\"\"\n",
    "    Get user id and ground truth\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    truth_path = os.path.join(input_split_path, f'train_truth_{split_id}.npy')\n",
    "    with open(truth_path, 'rb') as f:\n",
    "        truth = np.load(f)\n",
    "        \n",
    "    inp_user = truth[:,0]\n",
    "    out_age = torch.from_numpy(truth[:,1]).long()\n",
    "    out_gender = torch.from_numpy(truth[:,2]).long()\n",
    "    \n",
    "    del truth\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    if logger: logger.info(f'Target output ready after {time.time()-start:.2f}s')\n",
    "    return inp_user, out_age, out_gender\n",
    "\n",
    "def get_embed_seq(split_id, embed_var, inp_user, max_seq=100, train=True, logger=None):\n",
    "    \"\"\"\n",
    "    Get corresponding embedding sequence\n",
    "    \"\"\"\n",
    "    global inp_embed_artifact, input_split_path\n",
    "    assert embed_var in inp_embed_artifact\n",
    "    \n",
    "    start = time.time()\n",
    "    embedding = Word2Vec.load(inp_embed_artifact[embed_var]['embedding_artifact'])\n",
    "    if logger: logger.info(f'{embed_var.capitalize()} embedding artifact is loaded after {time.time()-start:.2f}s')\n",
    "    start = time.time()\n",
    "    file_prefix = inp_embed_artifact[embed_var]['train_file_prefix'] if train else inp_embed_artifact[embed_var]['test_file_prefix']\n",
    "    raw_path = os.path.join(input_split_path, f'{file_prefix}_{split_id}.json')\n",
    "    with open(raw_path, 'r') as f:\n",
    "        raw = json.load(f)\n",
    "    inp_seq = []\n",
    "    for user in inp_user:\n",
    "        inp_seq.append(torch.from_numpy(np.stack([embedding.wv[key] for key in raw[str(user)][:max_seq]], axis=0)).float())\n",
    "    inp_last_idx = np.array([i.shape[0] for i in inp_seq])-1\n",
    "    \n",
    "    del embedding, raw\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    if logger: logger.info(f'{embed_var.capitalize()} embedding sequence ready after {time.time()-start:.2f}s')\n",
    "    return inp_seq, inp_last_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(split_id, max_seq=100, logger=None):\n",
    "    \"\"\"\n",
    "    Get ground truth, and embedding sequence for creative, product and advertiser\n",
    "    \"\"\"\n",
    "    if logger: logger.info(f'Preparing Training Split-{split_id}')\n",
    "        \n",
    "    inp_user, out_age, out_gender = get_truth(split_id, logger=logger)\n",
    "    inp_creative_seq, inp_last_idx = get_embed_seq(split_id, 'creative',inp_user, max_seq=max_seq, logger=logger)\n",
    "    inp_advertiser_seq, _ = get_embed_seq(split_id, 'advertiser',inp_user, max_seq=max_seq, logger=logger)\n",
    "    inp_product_seq, _ = get_embed_seq(split_id, 'product',inp_user, max_seq=max_seq, logger=logger)\n",
    "    \n",
    "    del inp_user\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    return out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx   \n",
    "\n",
    "def prepare_test(split_id, max_seq=100, logger=None):\n",
    "    global input_split_path\n",
    "    if logger: logger.info(f'Preparing Training Split-{split_id}')\n",
    "        \n",
    "    idx_path = os.path.join(input_split_path, 'test_idx_shuffle.npy')\n",
    "    with open(idx_path, 'rb') as f:\n",
    "        test_idx = np.load(f)\n",
    "    inp_user = test_idx[(split_id-1)*100000:split_id*100000]\n",
    "    del test_idx\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    inp_creative_seq, inp_last_idx = get_embed_seq(split_id, 'creative',inp_user, max_seq=max_seq, train=False, logger=logger)\n",
    "    inp_advertiser_seq, _ = get_embed_seq(split_id, 'advertiser',inp_user, max_seq=max_seq, train=False, logger=logger)\n",
    "    inp_product_seq, _ = get_embed_seq(split_id, 'product',inp_user, max_seq=max_seq, train=False, logger=logger)\n",
    "    \n",
    "    _ = gc.collect()\n",
    "    \n",
    "    return inp_user, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Extraction_Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM feature extration layer\n",
    "    - Layer 1: BiLSTM + Dropout + Layernorm\n",
    "    - Layer 2: LSTM with Residual Connection + Dropout + Layernorm\n",
    "    - Layer 3: LSTM + Batchnorm + ReLU + Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, lstm_hidden_size, rnn_dropout=0.2, mlp_dropout=0.4, **kwargs):\n",
    "        super(LSTM_Extraction_Layer, self).__init__(**kwargs)\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        self.mlp_dropout = mlp_dropout\n",
    "        \n",
    "        self.bi_lstm = nn.LSTM(input_size=embed_size, hidden_size=lstm_hidden_size, bias=True, bidirectional=True)\n",
    "        self.rnn_dropout_1 = nn.Dropout(p=rnn_dropout)\n",
    "        self.layernorm_1 = nn.LayerNorm(2*lstm_hidden_size)\n",
    "        self.lstm_1 = nn.LSTM(input_size=2*lstm_hidden_size, hidden_size=2*lstm_hidden_size)\n",
    "        self.rnn_dropout_2 = nn.Dropout(p=rnn_dropout)\n",
    "        self.layernorm_2 = nn.LayerNorm(2*lstm_hidden_size)\n",
    "        self.lstm_2 = nn.LSTM(input_size=2*lstm_hidden_size, hidden_size=2*lstm_hidden_size)\n",
    "        self.batchnorm = nn.BatchNorm1d(2*lstm_hidden_size)\n",
    "        self.mlp_dropout = nn.Dropout(p=mlp_dropout)\n",
    "        \n",
    "    def forward(self, inp_embed, inp_last_idx):\n",
    "        bilstm_out, _ = self.bi_lstm(inp_embed.permute(1,0,2))                            # (max_seq_length, batch_size, embed_size) -> (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        bilstm_out = self.layernorm_1(self.rnn_dropout_1(bilstm_out))                     # (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out, _ = self.lstm_1(bilstm_out)                                             # (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out = self.rnn_dropout_2(lstm_out)                                           # (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out = self.layernorm_2(lstm_out+bilstm_out)                                  # (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out, _ = self.lstm_2(lstm_out)                                               # (max_seq_length, batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out = lstm_out.permute(1,0,2)[np.arange(len(inp_last_idx)), inp_last_idx,:]  # (batch_size, 2*lstm_hidden_size)\n",
    "        lstm_out = self.mlp_dropout(F.relu(self.batchnorm(lstm_out)))                     # (batch_size, 2*lstm_hidden_size)\n",
    "        return lstm_out\n",
    "    \n",
    "class MLP_Classification_Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer Perception Classification Layer\n",
    "    - Layer 1: Linear + Batchnorm + ReLU + Dropout\n",
    "    - Layer 2: Linear + Batchnorm + ReLU + Dropout\n",
    "    - Layer 3: Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_size, out_size, dropout=0.4, **kwargs):\n",
    "        super(MLP_Classification_Layer, self).__init__(**kwargs)\n",
    "        self.inp_size = inp_size\n",
    "        self.out_size = out_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.mlp_1 = nn.Linear(inp_size, 1024)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(1024)\n",
    "        self.mlp_dropout_1 = nn.Dropout(p=dropout)\n",
    "        self.mlp_2 = nn.Linear(1024, 512)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(512)\n",
    "        self.mlp_dropout_2 = nn.Dropout(p=dropout)\n",
    "        self.mlp_3 = nn.Linear(512, out_size)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        mlp_out = self.mlp_1(inp)                                                         # (batch_size, 1024)\n",
    "        mlp_out = self.mlp_dropout_1(F.relu(self.batchnorm_1(mlp_out)))                   # (batch_size, 1024)\n",
    "        mlp_out = self.mlp_2(mlp_out)                                                     # (batch_size, 512)\n",
    "        mlp_out = self.mlp_dropout_2(F.relu(self.batchnorm_2(mlp_out)))                   # (batch_size, 512)\n",
    "        mlp_out = self.mlp_3(mlp_out)                                                     # (batch_size, out_size)\n",
    "        return mlp_out   \n",
    "    \n",
    "class Multi_Seq_LSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Use separate LSTM extractor to handle different sequences, concat them and feed backto multilayer perception classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_size, lstm_hidden_size, out_size, rnn_dropout=0.2, mlp_dropout=0.4, **kwargs):\n",
    "        super(Multi_Seq_LSTM_Classifier, self).__init__(**kwargs)\n",
    "        assert isinstance(embed_size, list) and isinstance(lstm_hidden_size, list) and len(embed_size)==len(lstm_hidden_size)\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        self.mlp_dropout = mlp_dropout\n",
    "        \n",
    "        self.n_extraction = len(embed_size)\n",
    "        self.mlp_inp_size = sum(map(lambda x:2*x, lstm_hidden_size))\n",
    "        \n",
    "        for index, (e_size, h_size) in enumerate(zip(embed_size, lstm_hidden_size)):\n",
    "            setattr(self, f'extraction_layer_{index}', LSTM_Extraction_Layer(e_size, h_size, rnn_dropout=rnn_dropout, mlp_dropout=mlp_dropout))\n",
    "        self.classification_layer = MLP_Classification_Layer(self.mlp_inp_size, out_size, dropout=mlp_dropout)\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        assert len(args)==self.n_extraction+1\n",
    "        \n",
    "        extract_buffer = [getattr(self, f'extraction_layer_{index}')(inp_embed, args[-1]) for index, inp_embed in enumerate(args[:-1])]\n",
    "        out = torch.cat(extract_buffer, 1)\n",
    "        out = self.classification_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Age Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 5\n",
    "BATCH_SIZE = 256\n",
    "div, mod = divmod(90000, BATCH_SIZE)\n",
    "N_BATCH = div + min(mod, 1)\n",
    "\n",
    "def train_age(model, loss_fn, optimizer, device, checkpoint_dir, checkpoint_prefix, logger=None, epoch_start=0):\n",
    "    global EPOCHES, BATCH_SIZE, N_BATCH, TEST_SIZE\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    for epoch in range(1+epoch_start, EPOCHES+1+epoch_start):\n",
    "        if logger: \n",
    "            logger.info('=========================')\n",
    "            logger.info(f'Processing Epoch {epoch}/{EPOCHES+epoch_start}')\n",
    "            logger.info('=========================')\n",
    "            \n",
    "        train_file = [1,2,3,4,5,6,7,8,9]\n",
    "        test_file = [10]\n",
    "            \n",
    "        train_running_loss, train_n_batch = 0, 0\n",
    "        pred_y, true_y = [], []\n",
    "        for index, split_id in enumerate(train_file, start=1):\n",
    "            out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx = prepare_train(split_id)\n",
    "            model.train()\n",
    "            \n",
    "            for batch_index in range(N_BATCH):\n",
    "                x1 = torch.nn.utils.rnn.pad_sequence(inp_creative_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x2 = torch.nn.utils.rnn.pad_sequence(inp_advertiser_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x3 = torch.nn.utils.rnn.pad_sequence(inp_product_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x4 = inp_last_idx[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "                y = out_age[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                yp = F.softmax(model(x1, x2, x3, x4), 1)\n",
    "                loss = loss_fn(yp, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=100)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_running_loss += loss.item()\n",
    "                train_n_batch += 1\n",
    "                \n",
    "                del x1, x2, x3, x4, y, yp\n",
    "                _ = gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            if logger:\n",
    "                logger.info(f'Epoch {epoch}/{EPOCHES+epoch_start} - Training Split {index}/{len(train_file)} Done - Train Loss: {train_running_loss/train_n_batch:.6f}')\n",
    "            \n",
    "            del out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx\n",
    "            _ = gc.collect()\n",
    "            torch.cuda.empty_cache()   \n",
    "        \n",
    "        model.eval()\n",
    "        test_running_loss, test_n_batch = 0, 0\n",
    "        true_y, pred_y = [], []\n",
    "        \n",
    "        for index, split_id in enumerate(test_file, start=1):\n",
    "            out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx = prepare_train(split_id)\n",
    "            for batch_index in range(N_BATCH):\n",
    "                x1 = torch.nn.utils.rnn.pad_sequence(inp_creative_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x2 = torch.nn.utils.rnn.pad_sequence(inp_advertiser_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x3 = torch.nn.utils.rnn.pad_sequence(inp_product_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x4 = inp_last_idx[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "                y = out_age[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE].to(device)\n",
    "                yp = F.softmax(model(x1, x2, x3, x4), 1)\n",
    "                loss = loss_fn(yp, y)\n",
    "            \n",
    "                test_running_loss += loss.item()\n",
    "                test_n_batch += 1\n",
    "            \n",
    "                pred_y.extend(list(yp.cpu().detach().numpy()))\n",
    "                true_y.extend(list(y.cpu().detach().numpy()))\n",
    "            \n",
    "                del x1, x2, x3, x4, y, yp\n",
    "                _ = gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            del out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx\n",
    "            _ = gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        pred = np.argmax(np.array(pred_y), 1)\n",
    "        true = np.array(true_y).reshape((-1,))\n",
    "        acc_score = accuracy_score(true, pred)\n",
    "        \n",
    "        if logger:\n",
    "            logger.info(f'Epoch {epoch}/{EPOCHES+epoch_start} Done - Test Loss: {test_running_loss/test_n_batch:.6f}, Test Accuracy: {acc_score:.6f}')\n",
    "            \n",
    "        ck_file_name = f'{checkpoint_prefix}_{epoch}.pth'\n",
    "        ck_file_path = os.path.join(checkpoint_dir, ck_file_name)\n",
    "        \n",
    "        torch.save(model.state_dict(), ck_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:40:16 INFO: =========================\n",
      "07:40:16 INFO: Processing Epoch 1/5\n",
      "07:40:16 INFO: =========================\n",
      "07:46:12 INFO: Epoch 1/5 - Training Split 1/9 Done - Train Loss: 2.137750\n",
      "07:52:21 INFO: Epoch 1/5 - Training Split 2/9 Done - Train Loss: 2.123506\n",
      "07:58:28 INFO: Epoch 1/5 - Training Split 3/9 Done - Train Loss: 2.114756\n",
      "08:04:33 INFO: Epoch 1/5 - Training Split 4/9 Done - Train Loss: 2.108503\n",
      "08:10:39 INFO: Epoch 1/5 - Training Split 5/9 Done - Train Loss: 2.103345\n",
      "08:16:41 INFO: Epoch 1/5 - Training Split 6/9 Done - Train Loss: 2.099431\n",
      "08:22:41 INFO: Epoch 1/5 - Training Split 7/9 Done - Train Loss: 2.095377\n",
      "08:28:42 INFO: Epoch 1/5 - Training Split 8/9 Done - Train Loss: 2.092019\n",
      "08:34:43 INFO: Epoch 1/5 - Training Split 9/9 Done - Train Loss: 2.089040\n",
      "08:37:49 INFO: Epoch 1/5 Done - Test Loss: 2.065752, Test Accuracy: 0.385378\n",
      "08:37:49 INFO: =========================\n",
      "08:37:49 INFO: Processing Epoch 2/5\n",
      "08:37:49 INFO: =========================\n",
      "08:43:45 INFO: Epoch 2/5 - Training Split 1/9 Done - Train Loss: 2.063969\n",
      "08:49:47 INFO: Epoch 2/5 - Training Split 2/9 Done - Train Loss: 2.061952\n",
      "08:55:51 INFO: Epoch 2/5 - Training Split 3/9 Done - Train Loss: 2.060968\n",
      "09:01:55 INFO: Epoch 2/5 - Training Split 4/9 Done - Train Loss: 2.059977\n",
      "09:08:01 INFO: Epoch 2/5 - Training Split 5/9 Done - Train Loss: 2.058912\n",
      "09:14:13 INFO: Epoch 2/5 - Training Split 6/9 Done - Train Loss: 2.058248\n",
      "09:20:18 INFO: Epoch 2/5 - Training Split 7/9 Done - Train Loss: 2.057306\n",
      "09:26:20 INFO: Epoch 2/5 - Training Split 8/9 Done - Train Loss: 2.056278\n",
      "09:32:25 INFO: Epoch 2/5 - Training Split 9/9 Done - Train Loss: 2.055300\n",
      "09:35:32 INFO: Epoch 2/5 Done - Test Loss: 2.042362, Test Accuracy: 0.409256\n",
      "09:35:33 INFO: =========================\n",
      "09:35:33 INFO: Processing Epoch 3/5\n",
      "09:35:33 INFO: =========================\n",
      "09:41:31 INFO: Epoch 3/5 - Training Split 1/9 Done - Train Loss: 2.046796\n",
      "09:47:38 INFO: Epoch 3/5 - Training Split 2/9 Done - Train Loss: 2.045482\n",
      "09:53:46 INFO: Epoch 3/5 - Training Split 3/9 Done - Train Loss: 2.044550\n",
      "09:59:53 INFO: Epoch 3/5 - Training Split 4/9 Done - Train Loss: 2.044014\n",
      "10:06:00 INFO: Epoch 3/5 - Training Split 5/9 Done - Train Loss: 2.043495\n",
      "10:12:05 INFO: Epoch 3/5 - Training Split 6/9 Done - Train Loss: 2.043220\n",
      "10:18:09 INFO: Epoch 3/5 - Training Split 7/9 Done - Train Loss: 2.042714\n",
      "10:24:11 INFO: Epoch 3/5 - Training Split 8/9 Done - Train Loss: 2.042300\n",
      "10:30:16 INFO: Epoch 3/5 - Training Split 9/9 Done - Train Loss: 2.041732\n",
      "10:33:24 INFO: Epoch 3/5 Done - Test Loss: 2.039149, Test Accuracy: 0.412911\n",
      "10:33:24 INFO: =========================\n",
      "10:33:24 INFO: Processing Epoch 4/5\n",
      "10:33:24 INFO: =========================\n",
      "10:39:19 INFO: Epoch 4/5 - Training Split 1/9 Done - Train Loss: 2.037234\n",
      "10:45:24 INFO: Epoch 4/5 - Training Split 2/9 Done - Train Loss: 2.037378\n",
      "10:51:25 INFO: Epoch 4/5 - Training Split 3/9 Done - Train Loss: 2.036821\n",
      "10:57:28 INFO: Epoch 4/5 - Training Split 4/9 Done - Train Loss: 2.036289\n",
      "11:03:29 INFO: Epoch 4/5 - Training Split 5/9 Done - Train Loss: 2.035882\n",
      "11:09:32 INFO: Epoch 4/5 - Training Split 6/9 Done - Train Loss: 2.035800\n",
      "11:15:34 INFO: Epoch 4/5 - Training Split 7/9 Done - Train Loss: 2.035397\n",
      "11:21:39 INFO: Epoch 4/5 - Training Split 8/9 Done - Train Loss: 2.035174\n",
      "11:27:41 INFO: Epoch 4/5 - Training Split 9/9 Done - Train Loss: 2.035033\n",
      "11:30:52 INFO: Epoch 4/5 Done - Test Loss: 2.034043, Test Accuracy: 0.419000\n",
      "11:30:52 INFO: =========================\n",
      "11:30:52 INFO: Processing Epoch 5/5\n",
      "11:30:52 INFO: =========================\n",
      "11:36:51 INFO: Epoch 5/5 - Training Split 1/9 Done - Train Loss: 2.034805\n",
      "11:42:57 INFO: Epoch 5/5 - Training Split 2/9 Done - Train Loss: 2.033731\n",
      "11:49:03 INFO: Epoch 5/5 - Training Split 3/9 Done - Train Loss: 2.032841\n",
      "11:55:09 INFO: Epoch 5/5 - Training Split 4/9 Done - Train Loss: 2.032317\n",
      "12:01:18 INFO: Epoch 5/5 - Training Split 5/9 Done - Train Loss: 2.031989\n",
      "12:07:24 INFO: Epoch 5/5 - Training Split 6/9 Done - Train Loss: 2.031583\n",
      "12:13:28 INFO: Epoch 5/5 - Training Split 7/9 Done - Train Loss: 2.031188\n",
      "12:19:35 INFO: Epoch 5/5 - Training Split 8/9 Done - Train Loss: 2.030675\n",
      "12:25:39 INFO: Epoch 5/5 - Training Split 9/9 Done - Train Loss: 2.030298\n",
      "12:28:48 INFO: Epoch 5/5 Done - Test Loss: 2.032854, Test Accuracy: 0.418733\n"
     ]
    }
   ],
   "source": [
    "model = Multi_Seq_LSTM_Classifier([160, 128, 128], [256, 256, 256], 10).to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = DEVICE\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "checkpoint_dir = os.path.join(model_path, 'Multi_Seq_LSTM_Classifier_Creative_Advertiser_Product_Age')\n",
    "checkpoint_prefix = 'Multi_Seq_LSTM_Classifier_Creative_Advertiser_Product_Age'\n",
    "\n",
    "train_age(model, loss_fn, optimizer, device, checkpoint_dir, checkpoint_prefix, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:45:19 INFO: =========================\n",
      "12:45:19 INFO: Processing Epoch 6/10\n",
      "12:45:19 INFO: =========================\n",
      "12:51:17 INFO: Epoch 6/10 - Training Split 1/9 Done - Train Loss: 2.026355\n",
      "12:57:26 INFO: Epoch 6/10 - Training Split 2/9 Done - Train Loss: 2.026364\n",
      "13:03:32 INFO: Epoch 6/10 - Training Split 3/9 Done - Train Loss: 2.025312\n",
      "13:09:42 INFO: Epoch 6/10 - Training Split 4/9 Done - Train Loss: 2.025212\n",
      "13:15:48 INFO: Epoch 6/10 - Training Split 5/9 Done - Train Loss: 2.024471\n",
      "13:21:54 INFO: Epoch 6/10 - Training Split 6/9 Done - Train Loss: 2.024291\n",
      "13:28:01 INFO: Epoch 6/10 - Training Split 7/9 Done - Train Loss: 2.023931\n",
      "13:34:06 INFO: Epoch 6/10 - Training Split 8/9 Done - Train Loss: 2.023714\n",
      "13:40:12 INFO: Epoch 6/10 - Training Split 9/9 Done - Train Loss: 2.023405\n",
      "13:43:24 INFO: Epoch 6/10 Done - Test Loss: 2.027633, Test Accuracy: 0.425144\n",
      "13:43:24 INFO: =========================\n",
      "13:43:24 INFO: Processing Epoch 7/10\n",
      "13:43:24 INFO: =========================\n",
      "13:49:21 INFO: Epoch 7/10 - Training Split 1/9 Done - Train Loss: 2.021880\n",
      "13:55:30 INFO: Epoch 7/10 - Training Split 2/9 Done - Train Loss: 2.021543\n",
      "14:01:34 INFO: Epoch 7/10 - Training Split 3/9 Done - Train Loss: 2.021204\n",
      "14:07:38 INFO: Epoch 7/10 - Training Split 4/9 Done - Train Loss: 2.020917\n",
      "14:13:43 INFO: Epoch 7/10 - Training Split 5/9 Done - Train Loss: 2.020247\n",
      "14:19:50 INFO: Epoch 7/10 - Training Split 6/9 Done - Train Loss: 2.020182\n",
      "14:25:55 INFO: Epoch 7/10 - Training Split 7/9 Done - Train Loss: 2.020053\n",
      "14:32:02 INFO: Epoch 7/10 - Training Split 8/9 Done - Train Loss: 2.019799\n",
      "14:38:06 INFO: Epoch 7/10 - Training Split 9/9 Done - Train Loss: 2.019610\n",
      "14:41:20 INFO: Epoch 7/10 Done - Test Loss: 2.026283, Test Accuracy: 0.426700\n",
      "14:41:20 INFO: =========================\n",
      "14:41:20 INFO: Processing Epoch 8/10\n",
      "14:41:20 INFO: =========================\n",
      "14:47:17 INFO: Epoch 8/10 - Training Split 1/9 Done - Train Loss: 2.016018\n",
      "14:53:22 INFO: Epoch 8/10 - Training Split 2/9 Done - Train Loss: 2.016927\n",
      "14:59:26 INFO: Epoch 8/10 - Training Split 3/9 Done - Train Loss: 2.016730\n",
      "15:05:31 INFO: Epoch 8/10 - Training Split 4/9 Done - Train Loss: 2.017377\n",
      "15:11:35 INFO: Epoch 8/10 - Training Split 5/9 Done - Train Loss: 2.017080\n",
      "15:17:43 INFO: Epoch 8/10 - Training Split 6/9 Done - Train Loss: 2.016981\n",
      "15:23:49 INFO: Epoch 8/10 - Training Split 7/9 Done - Train Loss: 2.016729\n",
      "15:29:57 INFO: Epoch 8/10 - Training Split 8/9 Done - Train Loss: 2.016495\n",
      "15:36:05 INFO: Epoch 8/10 - Training Split 9/9 Done - Train Loss: 2.016308\n",
      "15:39:14 INFO: Epoch 8/10 Done - Test Loss: 2.023327, Test Accuracy: 0.430011\n",
      "15:39:14 INFO: =========================\n",
      "15:39:14 INFO: Processing Epoch 9/10\n",
      "15:39:14 INFO: =========================\n",
      "15:45:11 INFO: Epoch 9/10 - Training Split 1/9 Done - Train Loss: 2.014871\n",
      "15:51:19 INFO: Epoch 9/10 - Training Split 2/9 Done - Train Loss: 2.015177\n",
      "15:57:23 INFO: Epoch 9/10 - Training Split 3/9 Done - Train Loss: 2.014856\n",
      "16:03:28 INFO: Epoch 9/10 - Training Split 4/9 Done - Train Loss: 2.014802\n",
      "16:09:34 INFO: Epoch 9/10 - Training Split 5/9 Done - Train Loss: 2.014487\n",
      "16:15:41 INFO: Epoch 9/10 - Training Split 6/9 Done - Train Loss: 2.014527\n",
      "16:21:45 INFO: Epoch 9/10 - Training Split 7/9 Done - Train Loss: 2.014382\n",
      "16:27:49 INFO: Epoch 9/10 - Training Split 8/9 Done - Train Loss: 2.013949\n",
      "16:33:53 INFO: Epoch 9/10 - Training Split 9/9 Done - Train Loss: 2.013781\n",
      "16:37:03 INFO: Epoch 9/10 Done - Test Loss: 2.024405, Test Accuracy: 0.427989\n",
      "16:37:03 INFO: =========================\n",
      "16:37:03 INFO: Processing Epoch 10/10\n",
      "16:37:03 INFO: =========================\n",
      "16:43:00 INFO: Epoch 10/10 - Training Split 1/9 Done - Train Loss: 2.012993\n",
      "16:49:04 INFO: Epoch 10/10 - Training Split 2/9 Done - Train Loss: 2.012751\n",
      "16:55:12 INFO: Epoch 10/10 - Training Split 3/9 Done - Train Loss: 2.012196\n",
      "17:01:16 INFO: Epoch 10/10 - Training Split 4/9 Done - Train Loss: 2.012639\n",
      "17:07:20 INFO: Epoch 10/10 - Training Split 5/9 Done - Train Loss: 2.012547\n",
      "17:13:24 INFO: Epoch 10/10 - Training Split 6/9 Done - Train Loss: 2.012646\n",
      "17:19:27 INFO: Epoch 10/10 - Training Split 7/9 Done - Train Loss: 2.012528\n"
     ]
    }
   ],
   "source": [
    "model = Multi_Seq_LSTM_Classifier([160, 128, 128], [256, 256, 256], 10)\n",
    "checkpoint_dir = os.path.join(model_path, 'Multi_Seq_LSTM_Classifier_Creative_Advertiser_Product_Age')\n",
    "checkpoint_prefix = 'Multi_Seq_LSTM_Classifier_Creative_Advertiser_Product_Age'\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'{checkpoint_prefix}_5.pth')))\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = DEVICE\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_age(model, loss_fn, optimizer, device, checkpoint_dir, checkpoint_prefix, logger=logger, epoch_start=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 5\n",
    "BATCH_SIZE = 512\n",
    "N_BATCH = 90000//BATCH_SIZE\n",
    "TEST_SIZE = 90000%BATCH_SIZE\n",
    "\n",
    "def train_age(model, loss_fn, optimizer, device, checkpoint_dir, checkpoint_prefix, logger=None, epoch_start=0):\n",
    "    global EPOCHES, BATCH_SIZE, N_BATCH, TEST_SIZE\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "    \n",
    "    for epoch in range(1+epoch_start, EPOCHES+1+epoch_start):\n",
    "        if logger: \n",
    "            logger.info('=========================')\n",
    "            logger.info(f'Processing Epoch {epoch}/{EPOCHES+epoch_start}')\n",
    "            logger.info('=========================')\n",
    "            \n",
    "        train_file = [1,2,3,4,5,6,7,8,9]\n",
    "        test_file = [10]\n",
    "            \n",
    "        train_running_loss, train_n_batch = 0, 0\n",
    "        pred_y, true_y = [], []\n",
    "        for index, split_id in enumerate(train_file, start=1):\n",
    "            out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx = prepare_train(split_id)\n",
    "            train_creative_seq, test_creative_seq = inp_creative_seq[:-TEST_SIZE], inp_creative_seq[-TEST_SIZE:]\n",
    "            train_advertiser_seq, test_advertiser_seq = inp_advertiser_seq[:-TEST_SIZE], inp_advertiser_seq[-TEST_SIZE:]\n",
    "            train_product_seq, test_product_seq = inp_product_seq[:-TEST_SIZE], inp_product_seq[-TEST_SIZE:]\n",
    "            train_last_idx, test_last_idx = inp_last_idx[:-TEST_SIZE], inp_last_idx[-TEST_SIZE:]\n",
    "            train_age, test_age = out_age[:-TEST_SIZE], out_age[-TEST_SIZE:]\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            for batch_index in range(N_BATCH):\n",
    "                x1 = torch.nn.utils.rnn.pad_sequence(train_creative_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x2 = torch.nn.utils.rnn.pad_sequence(train_advertiser_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x3 = torch.nn.utils.rnn.pad_sequence(train_product_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x4 = train_last_idx[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "                y = train_age[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                yp = F.softmax(model(x1, x2, x3, x4), 1)\n",
    "                loss = loss_fn(yp, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=100)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_running_loss += loss.item()\n",
    "                train_n_batch += 1\n",
    "                \n",
    "                del x1, x2, x3, x4, y, yp\n",
    "                _ = gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            x1 = torch.nn.utils.rnn.pad_sequence(test_creative_seq, batch_first=True, padding_value=0).to(device)\n",
    "            x2 = torch.nn.utils.rnn.pad_sequence(test_advertiser_seq, batch_first=True, padding_value=0).to(device)\n",
    "            x3 = torch.nn.utils.rnn.pad_sequence(test_product_seq, batch_first=True, padding_value=0).to(device)\n",
    "            x4 = test_last_idx\n",
    "            y = test_age.to(device)\n",
    "            yp = F.softmax(model(x1, x2, x3, x4), 1)\n",
    "            loss = loss_fn(yp, y)\n",
    "            \n",
    "            pred_y.extend(list(yp.cpu().detach().numpy()))\n",
    "            true_y.extend(list(y.cpu().detach().numpy()))\n",
    "            \n",
    "            del x1, x2, x3, x4, y, yp\n",
    "            _ = gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            pred = np.argmax(np.array(pred_y), 1)\n",
    "            true = np.array(true_y).reshape((-1,))\n",
    "            acc_score = accuracy_score(true, pred)\n",
    "            \n",
    "            if logger:\n",
    "                logger.info(f'Epoch {epoch}/{EPOCHES+epoch_start} - Training Split {index}/{len(train_file)} Done - Train Loss: {train_running_loss/train_n_batch:.6f}, Val Loss: {loss.item():.6f}, Val Accuracy: {acc_score:.6f}')\n",
    "            \n",
    "            del out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx\n",
    "            del train_creative_seq, test_creative_seq, train_advertiser_seq, test_advertiser_seq, train_product_seq, test_product_seq, train_last_idx, test_last_idx, train_age, test_age\n",
    "            _ = gc.collect()\n",
    "            torch.cuda.empty_cache()   \n",
    "        \n",
    "        model.eval()\n",
    "        test_running_loss, test_n_batch = 0, 0\n",
    "        true_y, pred_y = [], []\n",
    "        \n",
    "        for index, split_id in enumerate(test_file, start=1):\n",
    "            out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx = prepare_train(split_id)\n",
    "            for batch_index in range(N_BATCH+1):\n",
    "                x1 = torch.nn.utils.rnn.pad_sequence(inp_creative_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x2 = torch.nn.utils.rnn.pad_sequence(inp_advertiser_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x3 = torch.nn.utils.rnn.pad_sequence(inp_product_seq[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE], batch_first=True, padding_value=0).to(device)\n",
    "                x4 = inp_last_idx[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE]\n",
    "                y = out_age[batch_index*BATCH_SIZE:(batch_index+1)*BATCH_SIZE].to(device)\n",
    "                yp = F.softmax(model(x1, x2, x3, x4), 1)\n",
    "                loss = loss_fn(yp, y)\n",
    "            \n",
    "                test_running_loss += loss.item()\n",
    "                test_n_batch += 1\n",
    "            \n",
    "                pred_y.extend(list(yp.cpu().detach().numpy()))\n",
    "                true_y.extend(list(y.cpu().detach().numpy()))\n",
    "            \n",
    "                del x1, x2, x3, x4, y, yp\n",
    "                _ = gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            del out_age, out_gender, inp_creative_seq, inp_advertiser_seq, inp_product_seq, inp_last_idx\n",
    "            _ = gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        pred = np.argmax(np.array(pred_y), 1)\n",
    "        true = np.array(true_y).reshape((-1,))\n",
    "        acc_score = accuracy_score(true, pred)\n",
    "        \n",
    "        if logger:\n",
    "            logger.info(f'Epoch {epoch}/{EPOCHES+epoch_start} Done - Test Loss: {test_running_loss/test_n_batch:.6f}, Test Accuracy: {acc_score:.6f}')\n",
    "            \n",
    "        ck_file_name = f'{checkpoint_prefix}_{epoch}.pth'\n",
    "        ck_file_path = os.path.join(checkpoint_dir, ck_file_name)\n",
    "        \n",
    "        torch.save(model.state_dict(), ck_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
